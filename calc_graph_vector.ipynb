{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate graph vectors $\\vec{G}=\\left[S_{mean},\\sigma_S,Q,P_{mean},C_{mean},T,A,E^{glo},E^{loc}_{mean},EC_{mean}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_graph_vector( filename, thresholds ) :\n",
    "    #-------------------------------------------------------------------#   \n",
    "    #    Input arguments:                                               #\n",
    "    #        filename   – name of file containing connectivity matrix   #\n",
    "    #        thresholds – list containing thresholds of interest        #\n",
    "    #-------------------------------------------------------------------#\n",
    "    #=== import libraries\n",
    "    import numpy as np\n",
    "    import bct\n",
    "\n",
    "    #=== load matrix \n",
    "    A_raw = np.loadtxt(filename)\n",
    "    N = A_raw.shape[0]   # number of nodes\n",
    "    M_sat = N*(N-1)/2    # max number of connections \n",
    "\n",
    "    #=== parameters\n",
    "    N_rep_louvain = 10   # number of Louvain algorithm repetitions\n",
    "    N_measures = 10      # number of graph measures\n",
    "    gamma = 1            # Louvain resolution parameter\n",
    "\n",
    "    graph_measures = np.zeros([ len(thresholds), N_measures ])      # create empty output matrix\n",
    "    for thr in range(len(thresholds)) : \n",
    "        #=== thresholding \n",
    "        A = bct.threshold_proportional( A_raw, p=thresholds[thr], copy=True );\n",
    "        A[np.nonzero(A<0)] = 0                                      # ensure only positive weights\n",
    "        M_act = A[np.nonzero(A>0)].shape[0] / 2                     # actual number of nonzero connections\n",
    "        #=== calculate measures\n",
    "        #-- mean connection strenght \n",
    "        S = np.sum(A)/M_act\n",
    "        #-- connection strenght std\n",
    "        Svar = np.std(A[np.nonzero(A)])\n",
    "        #-- modularity\n",
    "        [M,Q] = bct.modularity_louvain_und(A, gamma)\n",
    "        for i in range(N_rep_louvain) :\n",
    "            [Mt,Qt] = bct.modularity_louvain_und(A, gamma)\n",
    "            if Qt > Q :\n",
    "                Q = Qt\n",
    "                M = Mt\n",
    "        #-- participation coefficient\n",
    "        P = np.mean(bct.participation_coef_sign(A, M))\n",
    "        #-- clustering \n",
    "        C = np.mean(bct.clustering_coef_wu(A))\n",
    "        #-- transitivity \n",
    "        T = bct.transitivity_wu(A)\n",
    "        #-- assortativity\n",
    "        Asso = bct.assortativity_wei(A)\n",
    "        #-- global & local efficiency \n",
    "        Eglo = bct.efficiency_wei(A)\n",
    "        Eloc = np.mean(bct.efficiency_wei(A, local=True))\n",
    "        #-- mean eigenvector centralit\n",
    "        Eig = np.mean(bct.eigenvector_centrality_und(A))\n",
    "        #=== write vector to matrix\n",
    "        graph_measures[thr] = [ S, Svar, Q, P, C, T, Asso, Eglo, Eloc, Eig ]\n",
    "\n",
    "    #=== save results to file\n",
    "    np.savetxt( filename[:-4]+'_GV.txt', graph_measures )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out subjects with all files ( 4 sessions $\\times$ 5 atlases $\\times$ 4 models )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#=== loop over files\n",
    "sub_counter = np.zeros(57)  # stores number of files per subjects\n",
    "for sub in range(1,57) :\n",
    "    for ses in range(1,5) :\n",
    "        for model in ['cor','par','cov','pre'] :\n",
    "            for atlas in ['pow','aal','dos','har','mul'] :\n",
    "                filename = 'data/matKFLB_sub' + str(sub).zfill(2) + '_ses' + str(ses) + '_' + atlas + '_' + model + '.txt'\n",
    "                if os.path.isfile(filename)==True :               # if file exists\n",
    "                    sub_counter[sub-1] = sub_counter[sub-1] + 1 \n",
    "#=== filter complete subjects\n",
    "sub_complete = np.nonzero(sub_counter==80)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running calc_graph_vector for data/matKFLB_sub01_ses1_pow_cor.txt\n",
      "Running calc_graph_vector for data/matKFLB_sub01_ses1_aal_cor.txt\n",
      "Running calc_graph_vector for data/matKFLB_sub01_ses1_dos_cor.txt\n",
      "Running calc_graph_vector for data/matKFLB_sub01_ses1_har_cor.txt\n",
      "Running calc_graph_vector for data/matKFLB_sub01_ses1_mul_cor.txt\n"
     ]
    }
   ],
   "source": [
    "#=== define thresholds\n",
    "thresholds = [ 0.05, 0.075, 0.1, 0.125, 0.15 ]\n",
    "#=== calculate graph measures for all files\n",
    "for sub in list(sub_complete) :\n",
    "    for ses in range(1,5) :\n",
    "        for model in ['cor','par','cov','pre'] :\n",
    "            for atlas in ['pow','aal','dos','har','mul'] :\n",
    "                filename = 'data/matKFLB_sub' + str(sub).zfill(2) + '_ses' + str(ses) + '_' + atlas + '_' + model + '.txt'\n",
    "                #=== do the job\n",
    "                print('Running calc_graph_vector for ' + filename)\n",
    "                calc_graph_vector(filename,thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
